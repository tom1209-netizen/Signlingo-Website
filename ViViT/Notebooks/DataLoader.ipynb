{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"elapsed":6875,"status":"error","timestamp":1693038735595,"user":{"displayName":"Bùi Đình Tuấn Anh","userId":"04364186425085514423"},"user_tz":-420},"id":"d-C3CseBEB2W","outputId":"01f363fd-1454-4a50-cca2-f0411e6825d7"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-02e7ff98d56f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import io\n","import imageio\n","import ipywidgets\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from keras import backend as K\n","import mediapipe as mp"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess Videos with MediaPipe and Black Background\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"elapsed":56955,"status":"error","timestamp":1692985748193,"user":{"displayName":"Bùi Đình Tuấn Anh","userId":"04364186425085514423"},"user_tz":-420},"id":"1MhaECOPDu10","outputId":"d35541a6-4eb6-4a4d-dd08-f076857dc769"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import mediapipe as mp\n","max_videos_per_class = 30  # Maximum videos to process per class\n","min_frames_required = 30  # Minimum frames required in each video\n","videos_to_skip = 3  #\n","mp_holistic = mp.solutions.holistic.Holistic(static_image_mode=False, min_detection_confidence=0.2, min_tracking_confidence=0.2)\n","mp_hands = mp.solutions.hands.Hands(static_image_mode=False, min_detection_confidence=0.2, min_tracking_confidence=0.2)\n","\n","def apply_mediapipe_holistic(frame):\n","    # Create a black background\n","    global mp_holistic\n","    black_frame = frame.copy()\n","    black_frame[:] = (0, 0, 0)\n","\n","    # Convert the frame to RGB (Mediapipe requires RGB input)\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Process the frame with Mediapipe Holistic\n","    results = mp_holistic.process(frame_rgb)\n","\n","    # Draw the pose landmarks with orange color\n","    if results.pose_landmarks:\n","        mp.solutions.drawing_utils.draw_landmarks(\n","            black_frame, results.pose_landmarks, mp.solutions.holistic.POSE_CONNECTIONS,\n","            landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(255, 165, 0), thickness=1, circle_radius=1),\n","            connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(255, 165, 0), thickness=1))\n","\n","    # Draw the left hand landmarks with blue color\n","    if results.left_hand_landmarks:\n","        mp.solutions.drawing_utils.draw_landmarks(\n","            black_frame, results.left_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS,\n","            landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=1, circle_radius=1),\n","            connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=1))\n","\n","    # Draw the right hand landmarks with purple color\n","    if results.right_hand_landmarks:\n","        mp.solutions.drawing_utils.draw_landmarks(\n","            black_frame, results.right_hand_landmarks, mp.solutions.holistic.HAND_CONNECTIONS,\n","            landmark_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(128, 0, 128), thickness=1, circle_radius=1),\n","            connection_drawing_spec=mp.solutions.drawing_utils.DrawingSpec(color=(128, 0, 128), thickness=1))\n","\n","    return black_frame\n","\n","# Define the path to the main dataset folder\n","main_dataset_path = '/content/drive/MyDrive/vivit/dataset/Videos'  # original video dataset foldedr\n","output_folder = '/content/drive/MyDrive/vivit/MediaPipeProcessed/Videos'  # Output folder \n","\n","# Make sure the output folder exists or create it\n","os.makedirs(output_folder, exist_ok=True)\n","\n","class_folders = os.listdir(main_dataset_path)\n","for class_index, class_folder in enumerate(class_folders):\n","    print(class_folder)\n","    class_folder_path = os.path.join(main_dataset_path, class_folder)\n","\n","    # Track the number of videos processed for each class\n","    videos_processed = 0\n","\n","    skipped_videos_per_class = []  # List to store skipped video names for each class\n","\n","    for filename in os.listdir(class_folder_path):\n","        if videos_processed >= max_videos_per_class:\n","            break  # Stop if we have reached the limit for this class\n","\n","        if videos_processed < videos_to_skip:\n","            # Skip the first 'videos_to_skip' videos in each class\n","            videos_processed += 1\n","            skipped_videos_per_class.append(filename)\n","            continue\n","\n","        video_file_path = os.path.join(class_folder_path, filename)\n","\n","        cap = cv2.VideoCapture(video_file_path)\n","        video_frames = []\n","\n","        frame_count = 0  # Count frames in the video\n","\n","        while cap.isOpened():\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            video_frames.append(frame)\n","            frame_count += 1\n","\n","        cap.release()\n","\n","        if frame_count >= min_frames_required:\n","            video = np.array(video_frames)\n","\n","            # Create black background frames for each video\n","            black_frames = np.zeros_like(video)\n","\n","            # Apply MediaPipe Holistic to each frame and overlay keypoints\n","            for i in range(video.shape[0]):\n","                black_frame = apply_mediapipe_holistic(video[i])\n","                black_frames[i] = black_frame\n","\n","            # Save processed videos with keypoints for each class in MP4 format\n","            class_output_folder = os.path.join(output_folder, class_folder)\n","            os.makedirs(class_output_folder, exist_ok=True)\n","\n","            output_video_path = os.path.join(class_output_folder, f'{class_index}_{videos_processed}.mp4')\n","            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","            out = cv2.VideoWriter(output_video_path, fourcc, 30, (black_frames.shape[2], black_frames.shape[1]))\n","\n","            for frame in black_frames:\n","                out.write(frame)\n","\n","            out.release()\n","\n","            videos_processed += 1\n","\n","    # Print the names of skipped videos for each class\n","    print(f\"Skipped videos in {class_folder}: {skipped_videos_per_class}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess data with pure Videos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3361,"status":"error","timestamp":1693038792749,"user":{"displayName":"Bùi Đình Tuấn Anh","userId":"04364186425085514423"},"user_tz":-420},"id":"5cORsGkEjXbq","outputId":"445a22a7-6fdb-463b-fc2b-4e0cd8762c23"},"outputs":[],"source":["vid_size = (128, 128)  # Update the video size as needed\n","max_videos_per_class = 30  # Maximum videos to select per class\n","min_frames_required = 30  # Minimum frames required\n","videos_to_skip = 0  # Number of videos to skip in each class\n","\n","def frame_crop_center(video, cropf):\n","    f, _, _, _ = video.shape\n","    startf = f // 2 - cropf // 2\n","    return video[startf:startf + cropf, :, :, :]\n","\n","# Define the path to the main dataset folder\n","main_dataset_path = '/content/drive/MyDrive/vivit/Videos'  # Originial video dataset folder \n","\n","\n","video_list = []\n","label_list = []\n","skipped_videos_per_class = {}  # To store the names of skipped videos\n","\n","class_folders = os.listdir(main_dataset_path)\n","for class_index, class_folder in enumerate(class_folders):\n","    print(class_folder)\n","    class_folder_path = os.path.join(main_dataset_path, class_folder)\n","\n","    # Track the number of videos processed for each class\n","    videos_processed = 0\n","\n","    skipped_videos_per_class[class_folder] = []\n","\n","    for filename in os.listdir(class_folder_path):\n","        if videos_processed >= max_videos_per_class:\n","            break  # Stop if we have reached the limit for this class\n","\n","        if videos_processed < videos_to_skip:\n","            # Skip the first 'videos_to_skip' videos in each class\n","            videos_processed += 1\n","            skipped_videos_per_class[class_folder].append(filename)\n","            continue\n","\n","        video_file_path = os.path.join(class_folder_path, filename)\n","\n","        cap = cv2.VideoCapture(video_file_path)\n","        video_frames = []\n","\n","        frame_count = 0  # Count frames in the video\n","\n","        while cap.isOpened():\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","            print(frame)\n","            video_frames.append(frame)\n","            print(type(frame))\n","\n","            frame_count += 1\n","\n","        cap.release()\n","\n","        if frame_count >= min_frames_required:\n","            video = np.array(video_frames)\n","\n","            # Resize and crop video frames\n","            L = []\n","            for i in range(video.shape[0]):\n","                frame = cv2.resize(video[i], vid_size, interpolation=cv2.INTER_CUBIC)\n","                L.append(frame)\n","\n","            video = np.asarray(L)\n","            video = frame_crop_center(video, 42)\n","\n","            video_list.append(video)\n","            label_list.append(class_index)  # Assign class index as label\n","\n","            videos_processed += 1\n","\n","# Convert lists to NumPy arrays\n","videos = np.array(video_list)\n","labels = np.array(label_list)\n","\n","output_folder = '/content/drive/MyDrive/vivit/ProcessedData/all'\n","os.makedirs(output_folder, exist_ok=True)\n","\n","# Save the videos and labels arrays as NumPy files\n","np.save('/content/drive/MyDrive/vivit/ProcessedData/all/videos.npy', videos)\n","np.save('/content/drive/MyDrive/vivit/ProcessedData/all/labels.npy', labels)\n","\n","print(\"Videos shape:\", videos.shape)\n","print(\"Labels shape:\", labels.shape)\n","\n","# Print the names of skipped videos for each class\n","for class_name, skipped_videos in skipped_videos_per_class.items():\n","    print(f\"Skipped videos in {class_name}: {skipped_videos}\")\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
